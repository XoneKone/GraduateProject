{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "\n",
    "import string\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences  # new!\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout,SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Embedding  # новая!\n",
    "from keras.callbacks import ModelCheckpoint  # новая!\n",
    "import os  # новая!\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  # новая!\n",
    "import matplotlib.pyplot as plt  # новая!\n",
    "import gensim\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import show, figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['What is the answer to everything?']\n",
    "token_index = {}\n",
    "\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "max_length = 6\n",
    "results = np.zeros(shape=(len(samples),\n",
    "                          max_length,\n",
    "                          max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1.\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# имя каталога для сохранения результатов:\n",
    "output_dir = 'model_output/dense'\n",
    "# обучение:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "# параметры векторного пространства слов:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "n_words_to_skip = 50\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "# архитектура полносвязанной сети:\n",
    "n_dense = 64\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,input_length=max_review_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "batch_size = 128\n",
    "# векторное пространство слов:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 # новое!\n",
    "# архитектура сверточного слоя:\n",
    "n_conv = 256 # фильтры, они же ядра\n",
    "k_conv = 3 # длина ядра\n",
    "# архитектура полносвязанного слоя:\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Векторное пространство слов:\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    " input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "# сверточный слой:\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# полносвязанный слой:\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "# выходной слой:\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "batch_size = 128\n",
    "# векторное пространство слов:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 # новое!\n",
    "# архитектура сверточного слоя:\n",
    "n_conv = 256 # фильтры, они же ядра\n",
    "k_conv = 3 # длина ядра\n",
    "# архитектура полносвязанного слоя:\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Векторное пространство слов:\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    " input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "# сверточный слой:\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# полносвязанный слой:\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "# выходной слой:\n",
    "model.add(Dense(3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# имя каталога для сохранения результатов:\n",
    "output_dir = 'model_output/LSTM'\n",
    "# обучение:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "# параметры векторного пространства слов:\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "# архитектура сети LSTM:\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    " input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(GRU(n_lstm, dropout=drop_lstm))\n",
    "model.add(Dense(3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ann_viz(model,  view=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Векторное пространство слов:\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    " input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "# сверточный слой:\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# полносвязанный слой:\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "# выходной слой:\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# имя каталога для сохранения результатов:\n",
    "output_dir = 'model_output/LSTM'\n",
    "# обучение:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "# параметры векторного пространства слов:\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "# архитектура сети LSTM:\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    " input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(GRU(n_lstm, dropout=drop_lstm))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_5 (Spatia  (None, 100, 64)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 256)               247296    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 888,067\n",
      "Trainable params: 888,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ANN Visualizer: Layer not supported for visualizing",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mann_viz\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mview\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\GraduateProject\\venv\\lib\\site-packages\\ann_visualizer\\visualize.py:123\u001B[0m, in \u001B[0;36mann_viz\u001B[1;34m(model, view, filename, title)\u001B[0m\n\u001B[0;32m    121\u001B[0m         c\u001B[38;5;241m.\u001B[39mnode(\u001B[38;5;28mstr\u001B[39m(n), label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mpxls[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m x\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mpxls[\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m pixels\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mclrmap, fontcolor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhite\u001B[39m\u001B[38;5;124m\"\u001B[39m);\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 123\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mANN Visualizer: Layer not supported for visualizing\u001B[39m\u001B[38;5;124m\"\u001B[39m);\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, hidden_layers_nr):\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39msubgraph(name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcluster_\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;28;01mas\u001B[39;00m c:\n",
      "\u001B[1;31mValueError\u001B[0m: ANN Visualizer: Layer not supported for visualizing"
     ]
    }
   ],
   "source": [
    "ann_viz(model,  view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_to_books = Path('D:/Dev/GraduateProject/raw_books/')\n",
    "stpwrds = stopwords.words('russian') + list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "books = []\n",
    "for x in path_to_books.rglob('*.txt'):\n",
    "    with open(x, 'r', encoding='utf-8') as r:\n",
    "        data = str(r.read())\n",
    "\n",
    "    books.append(data.replace('\\xa0', '').replace('\\t', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tk_books = []\n",
    "for book in books:\n",
    "    tk_books.append(sent_tokenize(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25762"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk_books[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = {'author': [], 'name': [], 'text': []}\n",
    "for book in tk_books:\n",
    "    data['author'].append(book[0])\n",
    "    data['name'].append(book[1])\n",
    "    data['text'].append(book[2:])\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['tag'] = [0, 1, 2]\n",
    "# 0 - фантастика\n",
    "# 1 - детектив\n",
    "# 2 - фэнтези"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Глава 1., Дом стоял на склоне холма на окpаин...\n",
       "1    [1\\nБыла половина октября, около одиннадцати у...\n",
       "2    [ПРОЛОГ\\n\\n1., О ХОББИТАХ., Рассказ у нас пойд...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author                                        Адамс Дуглас.\n",
      "name      Путеводитель по Галактике для путешествующих а...\n",
      "text      [Глава 1., Дом стоял на склоне холма на окpаин...\n",
      "tag                                                       0\n",
      "Name: 0, dtype: object\n",
      "author                                     Чэндлеp Раймонд.\n",
      "name                                          Глубокий сон.\n",
      "text      [1\\nБыла половина октября, около одиннадцати у...\n",
      "tag                                                       1\n",
      "Name: 1, dtype: object\n",
      "author                                      Дж.Р.Р.Толкиен.\n",
      "name                                       ВЛАСТЕЛИН КОЛЕЦ.\n",
      "text      [ПРОЛОГ\\n\\n1., О ХОББИТАХ., Рассказ у нас пойд...\n",
      "tag                                                       2\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, record in df.iterrows():\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1993ebd41842d1a86087c8af9dc2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = {'sentences': [], 'tag': []}\n",
    "for i, record in tqdm(df.iterrows()):\n",
    "    for sent in record['text']:\n",
    "        texts['sentences'].append(' '.join(\n",
    "            [remove_multiple_spaces(remove_numbers(remove_punctuation(w.lower()))) for w in word_tokenize(sent) if\n",
    "             w not in stpwrds]))\n",
    "        texts['tag'].append(record['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>глава</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дом стоял склоне холма окpаине гоpодка отдельн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>окна выходили шиpокую pавнину западной англии</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>с стоpоны посмотpеть дом тpидцать лет это квад...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>единственный кого дом чем то устpаивал аpтуp д...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36079</th>\n",
       "      <td>а сэм взял путь приречье подъехал круче закат ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36080</th>\n",
       "      <td>прощальные бледно золотистые лучи озарили торб...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36081</th>\n",
       "      <td>роза встретила подвинула кресло камину усадила...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36082</th>\n",
       "      <td>он глубоко вздохнул</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36083</th>\n",
       "      <td>–ну вернулся – сказал</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36084 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  tag\n",
       "0                                                глава      0\n",
       "1      дом стоял склоне холма окpаине гоpодка отдельн...    0\n",
       "2          окна выходили шиpокую pавнину западной англии    0\n",
       "3      с стоpоны посмотpеть дом тpидцать лет это квад...    0\n",
       "4      единственный кого дом чем то устpаивал аpтуp д...    0\n",
       "...                                                  ...  ...\n",
       "36079  а сэм взял путь приречье подъехал круче закат ...    2\n",
       "36080  прощальные бледно золотистые лучи озарили торб...    2\n",
       "36081  роза встретила подвинула кресло камину усадила...    2\n",
       "36082                                он глубоко вздохнул    2\n",
       "36083                              –ну вернулся – сказал    2\n",
       "\n",
       "[36084 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_res.to_csv('dataset_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}